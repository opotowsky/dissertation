\chapter{Introduction}
\label{ch:intro}

The realm of nuclear security involves parallel efforts in nonproliferation
(verification of treaty compliance, monitoring for smuggling, proper storage
and transportation of nuclear materials), cyber security, minimizing stocks of
weaponizable materials, disaster response training, and nuclear forensics. All
of these efforts have been continually improving, but there was a gap regarding
the ability of the \gls{US} to coordinate and respond to a nuclear incident,
especially with the technical portion of nuclear forensics: characterization
and analysis. After all, the first textbook on the topic was published in 2005
\cite{nftext_2005}. In 2006, the \gls{US} \gls{DHS} founded the \gls{NTNFC}
within the \gls{DNDO}, with the mission to establish a robust nuclear forensics
capability by attributing radioactive materials with demonstrable proof. This
endeavor was and is highly dependent on inter-agency cooperation. In
2017 \-- 2018, the \gls{DNDO} was absorbed into the newer \gls{CWMD} office, and
in 2019, much of the nuclear forensics research operation was moved to multiple
offices within the \gls{DOE} \gls{NNSA}. 

Multiple fields contribute to a nuclear forensics capability, such as
radiochemical separations, material collection techniques, detector technology,
material library development, and identifying forensic signatures. These needs
vary based on whether the material being collected is post-detonation (e.g.,
bomb debris) or pre-detonation (e.g., \glsreset{SNF}\gls{SNF}).  In the
pre-detonation realm, this project focuses on statistical methods to to model
\gls{SNF} production history using nondestructive detector measurements. 

\section{Motivation}
\label{sec:motivation}

Preventing nuclear terrorism is important work that has a role along the entire
lifetime of nuclear material, from the beginning (e.g., enrichment facility
inspections) to the end (e.g., \gls{SNF} management). The \gls{IAEA} tracks
reports of radioactive material out of regulatory control via the \gls{ITDB}
\cite{itdb}, and the incidents that are confirmed or likely to be related to
trafficking or malicious use are summarized in Figure \ref{fig:incidents}.
These are the circumstances in which a robust nuclear forensics capability is
beneficial.

\begin{figure}[!bht]
  \makebox[\textwidth][c]{\includegraphics[width=\linewidth]{./chapters/intro/nucleartrafficking.png}}
  \caption{Incidents reported to the \acrshort{IAEA} \acrshort{ITDB} related to 
           malicious use. Included are highly enriched uranium (12), 
           plutonium (2), plutonium-beryllium neutron sources (5) 
           \cite{itdb}}
  \label{fig:incidents}
\end{figure}

Nuclear forensics is an important aspect of deterring nuclear terrorism even
though it is not, at first glance, obvious preventative nuclear security.  The
most common defense of the field is that nuclear forensics deters state actors,
not terrorist organizations. While it is true that a strong capability
encourages governments to be more active in prevention of nuclear terrorism, it
can also deter the terrorist organizations as well by increasing their chances
of failure. Small destructive successes tend to be more valued than high-risk
mass destruction. Nuclear forensics can also assist in cutting off certain
suppliers of nuclear materials or technologies (e.g., nuclear specialists that
are only involved for financial reasons, access to state suppliers), building a
concrete barrier to nuclear terrorism.  Therefore, nuclear forensics is
considered to impede nuclear terrorism in both tangible and abstract ways
\cite{aps_aaas_forensics}.

Following the prevention value of nuclear forensics, it is important to
understand the process of the technical portion of the investigation and how
that can be improved.  In the event of a nuclear incident, such as the
retrieval of stolen \glsreset{SNM}\gls{SNM} or the detonation of a dirty bomb,
it is necessary to learn as much as possible about the source of the materials
in a timely manner. In the case of non-detonated \gls{SNM}, knowing the
processes that produced it is crucial to determine the chain of custody of the
interdicted material.  Section \ref{sec:nfneeds} covers the specific needs of
the nuclear forensics community for \gls{SNF} provenance, and Section
\ref{sec:statscontrib} discusses how computational approaches are useful, with
a focus on why statistical methods in particular are being pursued. 

\subsection{Needs in Nuclear Forensics}
\input{chapters/intro/forensics}
\label{sec:nfneeds}

\subsection{Contribution of Statistical Methods}
\input{chapters/intro/statlearning}
\label{sec:statscontrib}

\section{Methodology}
\label{sec:methodology}

As previously mentioned, the typical workflow of the technical portion of a
forensics investigation is to take and analyze measurements of an unknown
nuclear material. The measurements are compared to databases filled with
previously measured standard materials with known reactor parameters, and/or
the reactor parameters are calculated from empirical relationships.  As this
work focuses on \gls{SNF}, these measurements are elemental, chemical, and
radiological in nature.  Because creating databases from real measurements to
represent \gls{SNF} from reactor technologies from around the world is not
within the scope of this project, the database in this study will be created
from simulations via the \gls{SCALE} \cite{scale} system using \gls{ORIGEN}
\cite{origen}. 

\todo[inline]{transition}
The top panel in Figure \ref{fig:nfworkflows} shows an example technical nuclear
forensics workflow as it could occur in the real world for a pre-detonation
scenario.  After a sample is obtained, characterization begins.  Next, the
results of these techniques are then compared against existing standard
materials databases to obtain the desired reactor parameters. These steps would
be performed iteratively in a real investigation, first using non-destructive
measurements, and then destructive measurements.  The steps in Figure
\ref{fig:nfworkflows} are obtaining reactor history information, if available,
and reporting the results to the investigators. 

\begin{figure}[!tbh]
  \makebox[\textwidth][c]{\includegraphics[width=\linewidth]{./chapters/intro/ForensicsWorkflows.png}}
  \caption{Schematic comparing nuclear forensics workflow in the top panel with 
           two approaches that a research workflow could follow.}
  \label{fig:nfworkflows}
\end{figure}

Next, the middle and bottom panels in Figure \ref{fig:nfworkflows} are
analagous physical and computational experimental workflows, respectively.
Both panels would have validated measurements of \gls{SNF}; the middle panel
shows this being done in the laboratory and the bottom panel shows that these
are values from a simulation. The goal of an experimental laboratory study is
to test or develop empirical relationships between forensics signatures and the
desired reactor parameters. The goal of computational studies can be this,
finding new empirical relationships, or performing forensics workflows prior to
the implementation of new reactor technologies.  For studying alternative
measurement techniques or a slight difference in the overall approach, a
researcher would iterate through multiple studies using known materials to
probe sensitivities or other weaknesses in the procedure.

In the simulation and statistical learning paradigm, we need to determine how
much information to what quality is needed to train an \gls{ML} model;
the model must give appropriate predictions of reactor parameters given a set
of measurements from a \textit{test} sample. 
\todo[inline]{a bit out of place; maybe delete} 

After creating a set of gamma spectra corresponding to simulations of \gls{SNF}
resulting from chosen reactor operation conditions, the next step is to choose
an algorithm that performs model creation via statistical learning.
Statistical learners have varied strengths and weaknesses based on what is
being predicted and how they implement optimization.  Chosen for this study are
simple regression algorithms for burnup prediction: nearest neighbor and
decision trees.  For comparison, \acrfull{SVR} is used because it is known to
handle highly dimensional data sets well.  These algorithms are introduced in
Section \ref{sec:algs}.

After the training is complete, the results of each models' predictions must be
evaluated according to \gls{ML} best practices.  The machine-learned
model predicts the parameters of a previously unseen test set.  The difference
between the model predictions and the actual simulated parameters is known as
the testing error.  The testing error with respect to various specifications
such as the training set size, number of features, or algorithm parameters
provides insight into the model performance. These results are broadly known as
diagnostic plots and show if the predictions are due to good performance or bad
fitting. 

After the models are evaluated, it will be important to compare them both
against each other and against other computational forensics methods. Thus, a
Bayesian approach from the field of inverse problem theory will be used to give
the probability distribution of the predictions so that the statistically
generated predictions can be evaluated directly against other solutions, such
as the optimization-based method, \gls{INDEPTH}. 
\todo[inline]{This might not be possible, or robustly possible}

Next, information reduction (within the training and testing data sets) must be
used to investigate the extension of this workflow to the real world. The
primary example here is the reduction of information quality via gamma ray
detectors.  If an algorithm could overcome the limitations of gamma detection
and still provide useful results, this would warrant further studies and
perhaps be field-applicable.

Thus, ultimately, the goal is to answer the question \textit{How does the
ability to determine forensic-relevant spent nuclear fuel attributes using
statistical techniques degrade as less information is available?}. 

\section{Goals}

The main purpose of this work is to evaluate the utility of statistical methods
as an approach to determine nuclear forensics-relevant quantities as less
information is available. \Gls{ML} algorithms are used to train models to
provide these values (e.g., reactor type, time since irradiation, burnup) from
the available information, or statistical methods are used for probabilistic
matching.  The training data is simulated using \gls{ORIGEN}, which provides an
array of nuclide concentrations as the features ($X$) and the parameters of
interest ($y$) are provided from the simulation inputs.  Information reduction
is carried out using computationally generated gamma spectra; the radionuclide
concentrations from the simulations can be converted into gamma energies, which
then undergo a detector response calculation to represent real as-measured
gamma spectra as closely as possible.  \Gls{ML} best practices are used to
evaluate the performance of the chosen algorithms, and inverse problem theory
is used to provide an interval of confidence in the model predictions.
\todo[inline]{update me if necessary}

The necessary background is covered in Chapter \ref{ch:litrev}.  First, an
introduction to the broader field of nuclear forensics is in Section
\ref{sec:nfoverview} to place this work in the context of the technical mission
areas. After that, a short discussion of the field of \gls{ML}, the algorithms
used, and validation methods are in Section \ref{sec:mlback}.
\todo[inline]{this will have to be reworded after the lit review is updated}
Section \ref{sec:fcsim} includes information about the software used to
generate the training data and perform the predictions. Lastly, a review of
statistical methods being used in studies of forensics analysis is covered in
Section \ref{sec:stats4nf}. 

...........................................................................
\todo[inline]{Update after research chapters are flushed out}

After the existing work is discussed, the methodology and a demonstration of
the experimental components is introduced next in Chapter \ref{ch:demo_method}.
This will cover the simulated training data in Section \ref{sec:training}, the
the details for training models in Section \ref{sec:statmodel}, and the
process of model evaluation in Section \ref{sec:valid}.  

Finally, Chapter \ref{ch:proposal} summarizes the official thesis research
proposal. After the preparatory tasks are covered in Section \ref{sec:prep},
there are three experiments outlined in Sections \ref{sec:exp1},
\ref{sec:exp2}, and \ref{sec:exp3}. Qualitiative hypotheses as well as
alternative directions for risk mitgation are discussed throughout these
sections.  A detailed explanation of the method comparison step is covered next
in Section \ref{sec:modelcompare}.  Lastly, a projected timeline for the
completion of this project is in Section \ref{sec:timeline}.

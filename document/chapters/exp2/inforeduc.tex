\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{./chapters/exp1/methodology2.png}
  \caption{Second portion of the flowchart from Figure \ref{fig:method} being 
           described in this section.}
\end{figure}

The overall goal of this project is to determine how much information to what
quality is needed to train an \gls{ML} model that can provide \gls{SNF}
attribution by correctly predicting the reactor type, burnup, \gls{U235}
enrichment, and time since irradiation.  In this section, the information
quality is treated as the information reduction (i.e. decreasing energy
resolution) of processed gamma spectra in the training database.  This
detector-based treatment was not applied to the mass measurements from the
first experiment in Chapter \ref{ch:exp1} because studying measurement
techniques that can only be done in a lab is not the goal of this work.
Instead, field-deployable detectors are of interest.

This process is outlined here for the second experiment, in which a gamma
spectrum is computed for each sample in the database from the nuclide
activities in Section \ref{sec:training2}.  
The code \gls{GADRAS} \cite{gadras} developed at Sandia National Laboratories will provide
computational gamma spectra.  
This adds more than one layer of reduced information quality, which are listed here as an outline of the steps taken to
process the gamma spectra:

\begin{enumerate}
  \item \label{itm:1} The list of nuclides is limited to radionuclides.
  \item \label{itm:2} Instead of "perfect" radionuclide activity knowledge, 
        they are being measured by a gamma detector.
  \item \label{itm:3} The processing of the gamma spectra can be highly variable.
  \item \label{itm:4} The $\sqrt{n}$ error of counts-based detection is included. 
\end{enumerate}

Step \ref{itm:1} covers which radionuclides to include, which was previously
covered in Section \ref{sec:training2}. Step \ref{itm:2} is to obtain a gamma
spectrum for every \gls{SNF} entry in the database. This is done using the
\gls{GADRAS} tool, which applies a \gls{DRF} to the gamma lines from these
radionuclides. The input is a nuclide activity vector, and the output is an
array of energy bins (measured in $keV$), and the counts per energy bin.

The nuclide activity data did require some processing to be used in this way.
The activities that come from the \gls{ORIGEN} simulations are based on there
being $1\:MT$ of initial uranium-based fuel. Not only is this quantity an
unlikely amount to be smuggled, it would overwhelm a detector at the
\todo[inline]{fix this to be better technical explanation of dead time and pile
up} source-detector distances in \gls{GADRAS}. Therefore, the material (and
resulting nuclide activities) are scaled to be $1\:g$ of \gls{SNF}.

Regarding the input information for the \gls{GADRAS} calculations, the sources
are provided without any background; this is because any spectrum would undergo
background subtraction before further analysis. Additionally, the nuclides are
pre-decayed in \gls{ORIGEN} to correspond to various cooling times, but the
source age provided to \gls{GADRAS} needs to be a non-zero value. A source age
of $20\:minutes$ provides the expected peaks.

\begin{table}[!htb]
  \centering
  \includegraphics[width=\linewidth]{./chapters/exp2/gadras_detectors.png}
  \caption{Select details of 6 detector setups used to obtain gamma 
           spectra-based training databases.}
  \label{tbl:detsetups}
\end{table}

Training databases were created for the six detectors outlined in Table
\ref{tbl:detsetups}. They were chosen to compare the highest energy resolution
detector, a lab-based \gls{HPGe}, against the rest, in order of decreasing
energy resolution: portable \gls{HPGe}, \gls{CZT}, \gls{SrI2}, \gls{LaBr3}, and
\gls{NaI} detectors. This is displayed in the table by including the \gls{FWHM}
of the $661\:keV$ peak for Cs137. At this point, there are six versions of the
original database for each detector setup, but there is a full gamma spectrum
for each \gls{SNF} entry. It is not computationally prudent to use full gamma
spectra for training and testing, and so these spectra are processed; this is
step \ref{itm:3} from above, and is outlined as follows.

\begin{figure}[!htb]
  \makebox[\textwidth][c]{\includegraphics[width=\linewidth]{./chapters/exp2/energy_window_example.png}}
  \caption{Slice of an example gamma spectrum in one of the training databases
           showing the windows over the gamma energy peaks.}
  \todo[inline]{update?}
  \label{fig:enwindows}
\end{figure}

Explanation of Step \ref{itm:3} here. 

\begin{table}[!htb]
  \centering
  \includegraphics[width=0.4\linewidth]{./chapters/exp2/enlist_nucs.png}
  \caption{Nuclides that are represented by the gamma energy lines in the two . The entire 
           set of 12 nuclides belongs to the long list, and the 7 bold nuclides
           belong to the short list.}
  \label{tbl:enlistnucs}
\todo[inline]{placeholder list, update me.}
\end{table}

Lastly, step \ref{itm:4} involves the inclusion of the counting error for the
summed energy windows. This is quite simple, as statistical counting error of
$n$ counts is $\sqrt{n}$.  As in Section \ref{sec:inforeduc1}, this error gets
applied in the same way for the machine learning algorithms, where the uniform
error is applied randomly within the range $[r-\sqrt{r},r+\sqrt{r}]$ for each
summed energy window $r$. For the \gls{MLL} calculations, Equation
\ref{eq:mllunc} is used, where $\sigma_{j} = \sqrt{r}$.  \todo[inline]{make
sure variables are explained clearly, choosing r to match variables above, the
original variable choice comes from TAMU papers}

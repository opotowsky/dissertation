
\glsresetall

\chapter{Reactor Parameter Prediction Using Processed Gamma Spectra}
\label{ch:exp2}

This chapter covers the parameter prediction workflow using processed spectra
as the input features. The methodology from Chapter \ref{ch:exp1} is reapplied
with new implementations surrounding the training set moving beyond full
knowledge of nuclide masses to degraded knowledge of processed gamma spectra.
This is described in four sections that correspond to the four steps summarized
in Figure \ref{fig:method}. 

The full description of the simulations and training labels can be found in
Section \ref{sec:training1}.  Section \ref{sec:training2} provides the updates
on the features used in the training set.  This results in a set of \gls{SNF}
observations with the same known reactor operation parameters, i.e., labels
that are to be predicted, but new nuclide features. 

Next, the information reduction step is covered in Section
\ref{sec:inforeduc2}.  Here, computational gamma spectra are created via the
\gls{GADRAS} tool; six detectors with decreasing energy resolution were chosen.
The approach for processing the spectra from these detectors is outlined here
as well. 

The increasingly less-precise training data sets are input to a statistical
learner for the next step: training models.  These use the features (from
processed spectra) and labels (reactor parameters/simulation inputs) in the
training data sets to formulate a model.  This is introduced in Section
\ref{sec:statmodel1}, and the updates for this experiment are in Section
\ref{sec:statmodel2}. 

Lastly, the algorithms must be evaluated for their prediction performance when
given test samples (i.e., a new \gls{SNF} measurement that has no labels
according the to algorithm).  This follows much of what was introduced in
Section \ref{sec:eval1}, and the updates to the approach is shown in Section
\ref{sec:eval2}. 

\section{Training Data Simulation}
\label{sec:training2}
\input{chapters/exp2/training}

\section{Information Reduction}
\label{sec:inforeduc2}
\input{chapters/exp2/inforeduc}

\section{Statistical Learning Implementation}
\label{sec:statmodel2}
\input{chapters/exp2/statmodels}

\section{Performance Evaluation}
\label{sec:eval2}
\input{chapters/exp2/evaluation}

\section{Summary}

This chapter covers the details of the methodology in four main sections:
training set simulations, information reduction, statistical methods
implementation, and performance evaluation. This approach focuses on the
situation where there are only nuclides present in the training sets that 
are measured in a non-destructive manner, i.e., via gamma detectors. 

First, in Section \ref{sec:training2}, the training data is simulated using the
same inputs as in Section \ref{sec:training1}. For this training set, however,
the features tracked are 32 radionuclides.

Second, in Section \ref{sec:inforeduc2}, information reduction on the training
set is carried out using computationally generated gamma spectra.  The training
set is initially comprised of nuclide activities, and \gls{GADRAS} is used to
compute the gamma spectra via \gls{DRF}s for six detectors \cite{gadras} using
the inputs of the nuclide activity measurements for each \gls{SNF} entry.
Next, each detector-based training set undergoes three different methods of
processing the gamma spectra. First, an automatic peak search determines which
peaks will be tracked, which is different for each detector. Second, a list of
target gamma energies is created using an arbitrary intensity threshold, so
that the most likely te be detected gamma energies are tracked. Third, the
intensity threshold is increased so that the gamma energies list will both be
shorter and more likely to result in photopeaks at those locations.  The target
gamma energies are then found on each spectrum, then the counts over a window
are summed (the window size is determined by detector energy resolution). The
three lists are thus denoted as the auto, short, and long energy windows lists
in the upcoming discussion.  These training sets are intended to answer the
question of whether field-deployable detectors can give enough information
about radionuclides to be able to successfully attribute \gls{SNF}. 

Third, in Section \ref{sec:statmodel2}, the updates to the algorithm
implementation from Section \ref{sec:statmodel1} are covered. The three
algorithms, \textit{k}-nearest neighbors, decision trees, and \gls{MLL}
calculations, are used to train models to predict the four reactor parameters
of interest. The hyperparameter optimization was carried out with the new
training sets, and the values were averaged across detectors for each of the
three energy windows lists.  The scikit-learn predictions and the \gls{MLL}
calculations were deployed using \gls{UW}--Madison's \gls{CHTC} resources, the
\gls{UW} campus grid, and the \gls{OSG} \cite{osg07, osg09}.  

Fourth, in Section \ref{sec:eval2}, the prediction errors are presented to
evaluate the ability of this methodology to attribute \gls{SNF} with
non-destructive measurements of radionuclides. The reactor type classification
is discussed in Section \ref{sec:exp2_rxtr} and the regression cases are
discussed in Section \ref{sec:exp2_reg}.  The performance of the prediction of
reactor parameters is measured by using test cases drawn from the training set,
where there is a training set for each detector in this study.  Again, the
testing of the algorithms is accomplished using 5-fold \gls{CV} for the
scikit-learn algorithms, and by removing one test sample at a time from the
training set for the \gls{MLL} calculations.

The reactor type classification results are presented in Section
\ref{sec:exp2_rxtr}.  The \gls{MLL} calculations consistently perform the best
across the algorithms, and the short energy windows list has the best
performance across the energy windows lists.  Most of the misclassifications are
\gls{PWR} and \gls{PHWR} being labeled as \gls{BWR}.  The automatic peak
searching results in erratic behavior for the scikit-learn algorithms because
the high energy resolution detectors perform poorly but one of the lower energy
resolution detectors performed very well. 

Next, the regression cases are shown in Section \ref{sec:exp2_reg}.  The burnup
predictions for all the algorithms and energy windows lists outperform the
baseline, except in one case of \textit{k}-nearest neighbors being used with
the auto energy windows list.  The enrichment predictions for the set of six
detectors all falls below the baseline, however, and the time since irradiation
predictions all are very close to the baseline, with some points right above it
and some right below it.  The spread of outliers encompasses $3-17\%$ of the
training set depending on the case, and in most cases the magnitude of the
outlier errors is of significant concern, although most of the median errors
paint a better picture of the performance.  For all three regression cases,
there is little contrast among the three energy windows lists. The auto list
has more erratic behavior, and the short list has a slight but not significant
average performance over the long list. 



\glsresetall

\chapter{Reactor Parameter Prediction Using Processed Gamma Spectra}
\label{ch:exp2}

This chapter covers the parameter prediction workflow using processed spectra
as the input features. The methodology from Chapter \ref{ch:exp1} is reapplied
with new implementations surrounding the training set moving beyond full
knowledge of nuclide masses to degraded knowledge of processed gamma spectra.
This is described in four sections that correspond to the four steps summarized
in Figure \ref{fig:method2}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.7\linewidth]{./chapters/exp2/methodology2.png}
  \caption[Experimental methodology in Chapter \ref{ch:exp2}]
          {Flowchart of the experimental methodology and the way each step is 
           being implemented.}
  \label{fig:method2}
\end{figure}

The full description of the simulations and training labels can be found in
Section \ref{sec:training1}.  Section \ref{sec:training2} provides the updates
on the features used in the training set.  This results in a set of \gls{SNF}
observations with the same known reactor operation parameters, i.e., labels
that are to be predicted, but new nuclide features. 

Next, the information reduction step is covered in Section
\ref{sec:inforeduc2}.  Here, computational gamma spectra are created via the
\gls{GADRAS} tool; six detectors with decreasing energy resolution were chosen.
The approach for processing the spectra from these detectors is outlined here
as well. 

The increasingly less-precise training data sets are input to a statistical
learner for the next step: training models.  These use the features (from
processed spectra) and labels (reactor parameters/simulation inputs) in the
training data sets to formulate a model.  This is introduced in Section
\ref{sec:statmodel1}, and the updates for this experiment are in Section
\ref{sec:statmodel2}. 

Lastly, the algorithms must be evaluated for their prediction performance when
given test samples (i.e., a new \gls{SNF} measurement that has no labels
according the to algorithm).  This follows much of what was introduced in
Section \ref{sec:eval1}, and the updates to the approach is shown in Section
\ref{sec:eval2}. 

\section{Training Data Simulation}
\label{sec:training2}
\input{chapters/exp2/training}

\section{Information Reduction}
\label{sec:inforeduc2}
\input{chapters/exp2/inforeduc}

\section{Statistical Learning Implementation}
\label{sec:statmodel2}
\input{chapters/exp2/statmodels}

\section{Performance Evaluation}
\label{sec:eval2}
\input{chapters/exp2/evaluation}

\section{Summary}

This chapter covers the details of the methodology in four main sections:
training set simulations, information reduction, statistical methods
implementation, and performance evaluation. This approach focuses on the
situation where there are only nuclides present in the training sets that 
are measured in a non-destructive manner, i.e., via gamma detectors. 

First, in Section \ref{sec:training2}, the training data is simulated using the
same inputs as in Section \ref{sec:training1}. For this training set, however,
the features tracked are 32 radionuclides.

%Second, in Section \ref{sec:inforeduc2}, information reduction on the training
%set is carried out using computationally generated gamma spectra.  The training
%set is initially comprised of nuclide activities, and \gls{GADRAS} is used to
%compute the gamma spectra via \gls{DRF}s for six detectors \cite{gadras} using
%the inputs of the nuclide activity measurements for each \gls{SNF} entry.
%Next, each detector-based training set undergoes three different methods of
%processing the gamma spectra. First, an automatic peak search determines which
%peaks will be tracked, which is different for each detector. Second, a list of
%target gamma energies is created using an arbitrary intensity threshold, so
%that the most likely to be detected gamma energies are tracked. Third, the
%intensity threshold is increased so that the gamma energies list will both be
%shorter and more likely to result in photopeaks at those locations.  The target
%gamma energies are then found on each spectrum, then the counts over a window
%are summed (the window size is determined by detector energy resolution). The
%three lists are thus denoted as the auto, short, and long energy windows lists
%in the upcoming discussion.  These training sets are intended to answer the
%question of whether field-deployable detectors can give enough information
%about radionuclides to be able to successfully attribute \gls{SNF}. 

Second, in Section \ref{sec:inforeduc2}, information reduction on the training
set is carried out using computationally generated gamma spectra.  The training
set is initially comprised of nuclide activities, and \gls{GADRAS} computes the
gamma spectra via \gls{DRF}s for six detectors \cite{gadras} using the inputs
of the nuclide activity measurements for each \gls{SNF} entry.  Each
detector-based training set undergoes processing by summing the counts of the
bins of each energy window from three different lists: the auto, short, and
long energy windows lists.  These training sets are intended to answer the
question of whether field-deployable detectors can give enough information
about radionuclides to successfully attribute \gls{SNF}. 

Third, in Section \ref{sec:statmodel2}, the updates to the algorithm
implementation from Section \ref{sec:statmodel1} are covered. The three
algorithms, \textit{k}-nearest neighbors, decision trees, and \gls{MLL}
calculations, are used to train models to predict the four reactor parameters
of interest. The new training sets also first underwent hyperparameter
optimization.

Fourth, in Section \ref{sec:eval2}, the prediction errors are presented to
evaluate the ability of this methodology to attribute \gls{SNF} with
non-destructive measurements of radionuclides. The reactor type classification
is discussed in Section \ref{sec:exp2_rxtr} and the regression cases are
discussed in Section \ref{sec:exp2_reg}.  The performance of the prediction of
reactor parameters is measured by using test cases drawn from the training set.

The reactor type classification results are presented in Section
\ref{sec:exp2_rxtr}.  The \gls{MLL} calculations consistently perform the best
across the algorithms, and the short energy windows list has the best
performance across the energy windows lists.  Most of the misclassifications
are \gls{PWR} and \gls{PHWR} being labeled as \gls{BWR}.  The automatic peak
searching results in erratic behavior for the scikit-learn algorithms because
the high energy resolution detectors perform poorly but one of the lower energy
resolution detectors performed very well. Most of the algorithm-detector
combinations do not exceed the baseline, and the only cases that do are the
\gls{MLL} calculations for the lab-based \gls{HPGe} with all three energy
windows lists and the \gls{MLL} calculations for the \gls{SrI2} detector with
the auto energy windows list. \textit{Since most of the detector-based data
points do not exceed the baseline for balanced accuracy, reactor type
classification only meets the standard defined using mass-based information for
the four aforementioned cases and the three full-knowledge training sets.}

Next, the regression cases are shown in Section \ref{sec:exp2_reg}.  The burnup
predictions for all the algorithms and energy windows lists outperform the
baseline, except in one case of \textit{k}-nearest neighbors being used with
the auto energy windows list.  The enrichment predictions for the set of six
detectors all falls below the baseline, however, and the time since irradiation
predictions all are very close to the baseline, with some points right above it
and some right below it.  The spread of outliers encompasses $3-17\%$ of the
training set depending on the case, and in most cases the magnitude of the
outlier errors is of significant concern, although most of the median errors
paint a better picture of the performance.  \textit{Based on the performances
relative to the baseline for each regression case, burnup performs above the
standard, enrichment performs far under the standard, and time since
irradiation has several cases that perform on or near the baseline and thus are
very close to the minimum standard.}

For all three regression cases, there is little contrast among the three energy
windows lists. The auto list has more erratic behavior, and the short list has
a slight but not significant average performance over the long list.
\textit{This indicates that the performance of the methodology in this work is
largely independent of the gamma spectra processing approaches.}


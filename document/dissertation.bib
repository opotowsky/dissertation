
@inproceedings{serial_ml,
	title = {Separated {Plutonium} {Attribution} using {Machine} {Learning} {Techniques}},
	volume = {124},
	eprint = {https://epubs.ans.org/?a=49623&_ga=2.26421434.644585875.1626725786-1803871342.1626725786},
    booktitle = {Technology and {Policy} {Advancements} in {Nuclear} {Nonproliferation}, {Transactions of the American Nuclear Society}},
	publisher = {American Nuclear Society},
	author = {O'Neal, Patrick J. and Chirayath, Sunil S.},
	month = jun,
	year = {2021},
	pages = {428--431},
}

@article{mll_validate,
  title = {Experimental validation of a nuclear forensics methodology for source reactor-type discrimination of chemically separated plutonium},
  volume = {51},
  issn = {1738-5733},
  eprint = {http://www.sciencedirect.com/science/article/pii/S1738573318303036},
  doi = {10.1016/j.net.2018.11.003},
  abstract = {An experimental validation of a nuclear forensics methodology for the source reactor-type discrimination of separated weapons-useable plutonium is presented. The methodology uses measured values of intra-element isotope ratios of plutonium and fission product contaminants. MCNP radiation transport codes were used for various reactor core modeling and fuel burnup simulations. A reactor-dependent library of intra-element isotope ratio values as a function of burnup and time since irradiation was created from the simulation results. The experimental validation of the methodology was achieved by performing two low-burnup experimental irradiations, resulting in distinct fuel samples containing sub-milligram quantities of weapons-useable plutonium. The irradiated samples were subjected to gamma and mass spectrometry to measure several intra-element isotope ratios. For each reactor in the library, a maximum likelihood calculation was utilized to compare the measured and simulated intra-element isotope ratio values, producing a likelihood value which is proportional to the probability of observing the measured ratio values, given a particular reactor in the library. The measured intra-element isotope ratio values of both irradiated samples and its comparison with the simulation predictions using maximum likelihood analyses are presented. The analyses validate the nuclear forensics methodology developed.},
  number = {2},
  journal = {Nuclear Engineering and Technology},
  author = {Osborn, Jeremy M. and Glennon, Kevin J. and Kitcher, Evans D. and Burns, Jonathan D. and Folden, Charles M. and Chirayath, Sunil S.},
  month = apr,
  year = {2019},
  keywords = {Intra-element isotope ratios, Maximum likelihood, Nuclear forensics, Reactor-type discrimination, Weapons-useable plutonium},
  pages = {384--393}
}

@article{mll_sensitivity,
  title = {Sensitivity studies on a novel nuclear forensics methodology for source reactor-type discrimination of separated weapons grade plutonium},
  issn = {1738-5733},
  eprint = {http://www.sciencedirect.com/science/article/pii/S1738573318309434},
  doi = {10.1016/j.net.2019.02.019},
  abstract = {A recently published nuclear forensics methodology for source discrimination of separated weapons-grade plutonium utilizes intra-element isotope ratios and a maximum likelihood formulation to identify the most likely source reactor-type, fuel burnup and time since irradiation of unknown material. Sensitivity studies performed here on the effects of random measurement error and the uncertainty in intra-element isotope ratio values show that different intra-element isotope ratios have disproportionate contributions to the determination of the reactor parameters. The methodology is robust to individual errors in measured intra-element isotope ratio values and even more so for uniform systematic errors due to competing effects on the predictions from the selected intra-element isotope ratios suite. For a unique sample-model pair, simulation uncertainties of up to 28\% are acceptable without impeding successful source-reactor discrimination. However, for a generic sample with multiple plausible sources within the reactor library, uncertainties of 7\% or less may be required. The results confirm the critical role of accurate reactor core physics, fuel burnup simulations and experimental measurements in the proposed methodology where increased simulation uncertainty is found to significantly affect the capability to discriminate between the reactors in the library.},
  journal = {Nuclear Engineering and Technology},
  author = {Kitcher, Evans D. and Osborn, Jeremy M. and Chirayath, Sunil S.},
  month = feb,
  year = {2019},
  keywords = {Intra-element isotope ratios, Maximum likelihood, Nuclear forensics, Reactor-type discrimination, Sensitivity analysis},
}

@article{mll_method,
  title = {Nuclear {Forensics} {Methodology} for {Reactor}-{Type} {Attribution} of {Chemically} {Separated} {Plutonium}},
  volume = {201},
  issn = {0029-5450},
  eprint = {https://doi.org/10.1080/00295450.2017.1401442},
  doi = {10.1080/00295450.2017.1401442},
  number = {1},
  abstract = {A nuclear forensics methodology has been developed that is capable of source attribution of separated weapons-grade plutonium in case of an interdiction. The methodology utilizes plutonium and contaminant fission product isotopes within the separated plutonium sample to determine the characteristics (reactor parameters) of the interdicted material. The reactor parameters of interest include source reactor type, fuel irradiation burnup, and time since irradiation. The MCNPX-2.7 radiation transport code was used to model reactor cores and perform neutronics simulations to estimate the resulting isotopes of irradiated UO2 fuel. The simulation results were used to create a reactor-dependent library of irradiated fuel isotope ratio values as a function of fuel burnup and time since irradiation. Ratios of intra-element isotopes (fission product or actinide) are used as characteristics to determine a combination of reactor parameters of interest that could have produced the interdicted sample. The isotopes selected for the attribution methodology development were based upon the initial criteria of isotope production yield in fuel and half-life. Subsequently, intra-element isotope ratios were formed with the criterion that the ratio must have a functional dependence on at least one of the reactor parameters of interest. The developed methodology compares the values of reactor-dependent intra-element isotope ratios in the library developed to the same ratios of the interdicted sample. A maximum likelihood calculation methodology was utilized to perform the aforementioned multiple intra-element isotope ratio comparison to produce a single metric to depict the result of the comparison. The methodology can predict the reactor type, fuel burnup, and time since irradiation of the sample by selecting the array of reactor-dependent intra-element isotope ratios that provides the maximum likelihood value. The methodology was tested with intra-element ratios of pseudo interdicted sample data and found to be viable for source attribution.},
  journal = {Nuclear Technology},
  author = {Osborn, Jeremy M. and Kitcher, Evans D. and Burns, Jonathan D. and III, Charles M. Folden and Chirayath, Sunil S.},
  month = jan,
  year = {2018},
  keywords = {Nuclear forensics, attribution methodology, maximum likelihood},
  pages = {1--10},
}

@techreport{itdb,
  address = {Vienna, Austria},
  title = {{IAEA Incident and Trafficking Database: Incidents of nuclear and other radioactive material out of regulatory control}},
  eprint = {https://www.iaea.org/sites/default/files/20/02/itdb-factsheet-2020.pdf},
  number = {2020 Factsheet},
  institution = {International Atomic Energy Agency},
  author = {{Division of Nuclear Security}},
  year = {2020}
}

@article{bayes_compare,
  title = {Bayes in the {Sky}: {Bayesian} {Inference} and {Model} {Selection} in {Cosmology}},
  volume = {49},
  note = {Invited review},
  eprint = {https://ned.ipac.caltech.edu/level5/Sept13/Trotta/Trotta_contents.html},
  number = {2},
  journal = {Contemporary Physics},
  author = {Trotta, Roberto},
  year = {2008},
  pages = {71--104}
}

@techreport{gentle_bayes,
  address = {The Institute for Computational Engineering and Sciences},
  type = {Note. },
  title = {A {Gentle} {Tutorial} on {Statistical} {Inversion} using the {Bayesian} {Paradigm}},
  eprint = {http://users.ices.utexas.edu/~tanbui/teaching/Bayesian/Bayesian.pdf},
  number = {ICES REPORT 12-18},
  institution = {The University of Texas at Austin},
  author = {{Tan Bui-Thanh}},
  month = may,
  year = {2012}
}

@article{pu_discrimination,
  title = {Discrimination of source reactor type by multivariate statistical analysis of uranium and plutonium isotopic concentrations in unknown irradiated nuclear fuel material},
  volume = {99},
  eprint = {http://www.sciencedirect.com/science/article/pii/S0265931X08001203},
  abstract = {The problem of identifying the provenance of unknown nuclear material in the environment by multivariate statistical analysis of its uranium and/or plutonium isotopic composition is considered. Such material can be introduced into the environment as a result of nuclear accidents, inadvertent processing losses, illegal dumping of waste, or deliberate trafficking in nuclear materials. Various combinations of reactor type and fuel composition were analyzed using Principal Components Analysis (PCA) and Partial Least Squares Discriminant Analysis (PLSDA) of the concentrations of nine U and Pu isotopes in fuel as a function of burnup. Real-world variation in the concentrations of 234U and 236U in the fresh (unirradiated) fuel was incorporated. The U and Pu were also analyzed separately, with results that suggest that, even after reprocessing or environmental fractionation, Pu isotopes can be used to determine both the source reactor type and the initial fuel composition with good discrimination.},
  number = {11},
  journal = {Journal of Environmental Radioactivity},
  author = {Robel, Martin and Kristo, Michael J.},
  month = nov,
  year = {2008},
  pages = {1789--1797}
}

@misc{refmaterial,
  title = {Nuclear Forensic Reference Materials for Attribution of Urban Nuclear Terrorism},
  eprint = {https://www.nist.gov/system/files/documents/oles/7-Inn_Kenneth-Nuclear-Forensics-UVC-Project.pdf},
  author = {Kenneth G.W. Inn and Jacqueline Mann and Jeffrey Leggitt and JoAnne Buscaglia and Simon Jerome and John Molloy and William Pramenko},
  note = {\textit{Presentation for NIST}},
  year = {2015},
}

@article{changingml,
  title = {The changing science of machine learning},
  volume = {82},
  eprint = {https://link.springer.com/article/10.1007\%2Fs10994-011-5242-y},
  issue = {3},
  pages = {275--279},
  journal = {Machine Learning},
  author = {Langley, Pat},
  key = {Editorial},
  month = jan,
  year = {2011}
}

@article{nf_missingdata,
  title = {Nuclear forensics analysis with missing data},
  volume = {308},
  eprint = {http://link.springer.com/article/10.1007/s10967-015-4458-x},
  doi = {10.1007/s10967-015-4458-x},
  abstract = {We have applied a new imputation-based method for analyzing incomplete data, called Monte Carlo Bayesian Database Generation (MCBDG), to the spent fuel isotopic composition (SFCOMPO) database. About 60 \% of the entries in SFCOMPO are absent. The method estimates missing values of a property from a probability distribution created from the existing data for the property, and then generates
  iple instances of the completed database for training a machine learning algorithm. Uncertainty in the data is represented by an empirical or an assumed error distribution. The method makes few assumptions about the underlying data, and it compares favorably against results obtained by replacing missing information with constant values.},
  journal = {Journal of Radioanalytical and Nuclear Chemistry},
  author = {Langan, Roisin T. and Archibald, Richard K. and Lamberti, Vincent E.},
  year = {2016},
  pages = {687}
}

@techreport{iaea_nf,
  address = {Vienna, Austria},
 eprinttle = {Nuclear {Forensics} {Support}: {Technical} {Guidance} {Reference} {Manual}},
  eprint = {http://www-pub.iaea.org/MTCD/Publications/PDF/Pub1241_web.pdf},
  abstract = {Nuclear scientists have recognized that much can be learned from the analysis of reported cases of illicit trafficking of nuclear and other radioactive material, specifically, what the material has been used for, where it was obtained from (stock, scrap or waste) and whether the amount seized was only a sample of a much more significant quantity. These and many other questions can be answered through detailed technical characterization of seized material samples. The combination of scientific methods used for this purpose is normally referred to as nuclear forensics, which has become an indispensable tool for use in law enforcement investigations of nuclear trafficking. This publication is unique in bringing together for the first time a concise but comprehensive description of the various tools and procedures of nuclear forensic investigations that have been described independently in the scientific literature. It also incorporates the experience accumulated over the past decade by law enforcement agencies and nuclear forensics laboratories confronted with cases of illicit events involving nuclear or other radioactive materials.},
  institution = {{IAEA}},
  author = {M.J. Kristo and D.K. Smith and S. Niemeyer and G.D. Dudder and R. Abedin-Zadeh},
  year = {2006}
}

@article{dayman_feasibility_2013,
  title = {Feasibility of fuel cycle characterization using multiple nuclide signatures},
  volume = {296},
  eprint = {http://link.springer.com/article/10.1007\%2Fs10967-012-1987-4},
  doi = {10.1007/s10967-012-1987-4},
  abstract = {The feasibility of identifying spent nuclear fuel arising from an unknown fuel cycle in terms of reactor type and burnup using a database of nuclide composition vectors generated for combinations of these two variables is examined. The database and test cases were generated using ORIGEN-ARP, and the concentrations of 200 nuclides were analyzed for each sample. Nearest neighbors and ridge regression techniques were used to make predictions of the reactor type and burnup of test cases. Various truncated nuclide lists were also tested. An initial examination of the techniques’ sensitivity to measurement error was made by perturbing the unknowns’ composition vector and examining the effect on each of the technique’s predictions. We demonstrate through the results of these experiments that investigation and development of multivariate data analysis methodologies for nuclear forensics applications is warranted.},
  journal = {Journal of Radioanalytical and Nuclear Chemistry},
  author = {Dayman, Kenneth and Biegalski, Steven},
  year = {2013},
  pages = {195--201}
}

@book{elements_stats,
  address = {New York, NY, USA},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  title = {The {Elements} of {Statistical} {Learning}},
  year = 2001
}

@techreport{aps_aaas_forensics,
  title = {Nuclear {Forensics}: {Role}, {State} of the {Art}, and {Program} {Needs}},
  institution = {Joint Working Group of the American Physical Society and the American Association for the Advancement of Science},
  author = {Michael May and Reza Abedin-Zadeh and Donald Barr and Albert Carnesale and Philip E. Coyle and Jay Davis and William Dorland and William Dunlop and Steve Fetter and Alexander Glaser and Ian D. Hutcheon and Francis Slakey and Benn Tannenbaum},
  year = 2007, 
  eprint = {https://www.aaas.org/report/nuclear-forensics-role-state-art-program-needs},
}

@inproceedings{gey_search,
  address = {Dortmund, Germany},
  title = {Nuclear Forensics: A Scientific Search Problem},
  author = {Gey, Frederic and Reynolds, Chloe and Larson, Ray and Sutton, Electra},
  booktitle = {{Proceedings} of the {Lernen, Wissen, Adaption} ({Learning, Knowledge, Adaptation}) {Conference}},
  year = 2012,
  eprint = {http://metadata.berkeley.edu/nuclear-forensics/Paper_9-12-12_lwa-2012-nuclear-forensics-scientific-search-problem_v7.pdf},
}

@article{nicolaou_2015,
  title = {Plutonium fingerprinting in nuclear forensics of spent nuclear fuel},
  journal = {Progress in Nuclear Energy},
  volume = {85},
  number = {Supplement C},
  pages = {333--336},
  year = {2015},
  eprint = {http://www.sciencedirect.com/science/article/pii/S0149197015300329},
  author = {I. Lantzos and Ch Kouvalaki and G. Nicolaou},
}

@article{nicolaou_2014,
  title = {Discrimination of spent nuclear fuels in nuclear forensics through isotopic fingerprinting},
  volume = {72},
  eprint = {http://www.sciencedirect.com.ezproxy.library.wisc.edu/science/article/pii/S0306454914002308},
  doi = {10.1016/j.anucene.2014.05.016},
  abstract = {Isotopic fingerprinting in nuclear forensics, developed through a simulation study to resolve spent nuclear fuels from different reactors, has been applied on real samples from fuels irradiated in nuclear reactors. The U and Pu isotopics of the real samples, used as fingerprints, have been retrieved from the OECD/NEA SFCOMPO databank comprising compositions of spent nuclear fuels from their Post-Irradiation Examination at the End of their Irradiation (EOI). The method has grouped together nuclear spent fuels from the same reactor, resolving distinctly those with similar 235U enrichment. Furthermore, spent fuel pins of the same enrichment, from different positions within a reactor core, are resolved. Differentiating of the spent fuels has been achieved, whether (U, Pu) or Pu are used as fingerprints.},
  journal = {Annals of Nuclear Energy},
  author = {Nicolaou, G.},
  month = {Oct},
  year = {2014},
  note = {Technical Note},
  pages = {130--133}
}

@article{nicolaou_2009,
  title = {Identification of unknown irradiated nuclear fuel through its fission product content},
  volume = {279},
  eprint = {http://link.springer.com./article/10.1007\%2Fs10967-007-7300-x},
  doi = {10.1007/s10967-007-7300-x},
  abstract = {A procedure is demonstrated, through a simulation study, for the determination of the origin of unknown spent nuclear fuel, an important and challenging task in nuclear forensics. The procedure is an isotopic fingerprinting method relying on the fission product content of the unknown. The ‘unknown’ nuclear material is represented by the spent nuclear fuel of known origin in order to demonstrate the method and verify its predictive capabilities. The method is based on the comparison of the fission product compositions of the ‘unknown’ material and simulated known spent fuels from a range of commercial nuclear power stations using the multivariate statistical technique of factor analysis. Then, the provenance of the ‘unknown’ spent fuel is the commercial fuel with which it exhibits the highest similarity with respect to the fission product content.},
  number = {2},
  journal = {Journal of Radioanalytical and Nuclear Chemistry},
  author = {Nicolaou, G.},
  year = {2009},
  pages = {503--508}
}

@article{nicolaou_pu,
  title = {Provenance of unknown plutonium material},
  journal = {Journal of Environmental Radioactivity},
  volume = {99},
  number = {10},
  pages = {1708--1710},
  year = {2008},
  eprint = {http://www.sciencedirect.com/science/article/pii/S0265931X08000969},
  author = {G. Nicolaou},
}

@article{nicolaou_2006,
  title = {Determination of the origin of unknown irradiated nuclear fuel},
  volume = {86},
  eprint = {http://nuclear.ee.duth.gr/upload/A13\%20\%20\%20identification.pdf},
  doi = {10.1016/j.jenvrad.2005.09.007},
  abstract = {An isotopic fingerprinting method is presented to determine the origin of unknown nuclear material with forensic importance. Spent nuclear fuel of known origin has been considered as the ‘unknown’ nuclear material in order to demonstrate the method and verify its prediction capabilities. The method compares, using factor analysis, the measured U, Pu isotopic compositions of the ‘unknown’ material with U, Pu isotopic compositions simulating well known spent fuels from a range of commercial nuclear power stations. Then, the ‘unknown’ fuel has the same origin as the commercial fuel with which it exhibits the highest similarity in U, Pu compositions.},
  journal = {Journal of Environmental Radioactivity},
  author = {Nicolaou, G.},
  year = {2006},
  pages = {313--318}
}

@inproceedings{robel_2009,
  address = {Tuscon, AZ, USA},
  title = {Nuclear Forensic Inferences Using Iterative Multidimensional Statistics},
  eprint = {https://e-reports-ext.llnl.gov/pdf/374432.pdf},
  abstract = {Nuclear forensics involves the analysis ofinterdicted nuclear material for specific material characteristics (referred to as “signatures”) that imply specific geographical locations, production processes, culprit intentions, etc.  Predictive signatures rely on expert knowledge of physics, chemistry, and engineering to develop inferences from these material characteristics.  Comparative signatures, on the other hand, rely on comparison of the material characteristics of the interdicted sample (the “questioned sample” in FBI parlance) with those of a set of known samples.  In the ideal case, the set of known samples would be a comprehensive nuclear forensics database, a database which does not currently exist.  In fact, our ability to analyze interdicted samples and produce an extensive list of precise materials characteristics far exceeds our ability to interpret the results.  Therefore, as we seek to develop the extensive databases necessary for nuclear forensics, we must also develop the methods necessary to produce the necessary inferences from comparison of our analytical results with these large, multidimensional sets of data.   In the work reported here, we used a large, multidimensional dataset of results from quality control analyses of uranium ore concentrate (UOC, sometimes called “yellowcake”).  We have found that traditional multidimensional techniques, such as principal components analysis (PCA), are especially useful for understanding such datasets and drawing relevant conclusions. In particular, we have developed an iterative partial least squares-discriminant analysis (PLS-DA) procedure that has proven especially adept at identifying the production location of unknown UOC samples.  By removing classes which fell far outside the initial decision boundary, and then rebuilding the PLS-DA model, we have consistently produced better and more definitive attributions than with a single pass classification approach. Performance of the iterative PLS-DA method compared favorably to that of classification and regression tree (CART) and k nearest neighbor (KNN) algorithms,with the best combination of accuracy and robustness, as tested by classifying samples measured independently in our laboratories against the vendor QC based reference set.},
  booktitle = {{Proceedings} of the {Institute} of {Nuclear Materials Management} 50th {Annual Meeting}},
  publisher = {Institute of Nuclear Materials Management},
  author = {Robel, Martin and Kristo, Michael J. and Heller, Martin A.},
  month = {Jul},
  year = {2009},
  note = {LLNL-CONF-414001}
}

@inproceedings{jones_viz_2014,
  address = {Portland, Oregon},
  booktitle = {{Techniques} and {Methods} for {Safeguards, Nonproliferation} and {Arms Control Verification Workshop}},
  title = {Machine Learning for Classification and Visualisation of Radioactive Substances for Nuclear Forensics},
  eprint = {https://www.researchgate.net/publication/264352908_Machine_Learning_for_Classification_and_Visualisation_of_Radioactive_Substances_for_Nuclear_Forensics},
  abstract = {The IAEA (International Atomic Energy Agency) figures from 2012 show that there have been in excess of 2,331 reported cases of trafficking of radioactive materials worldwide[1]. The hazardous nature of this material means that trafficking of such substances is cause for concern and should be combatted appropriately. Nuclear forensics is a field that has emerged as an anti- proliferation solution to this problem by extracting forensic information from radioactive materials to answer questions about the source of such unknown materials. Traditionally the elemental and isotopic composition of the material can be analyzed to determine attributes of the materials history using known characteristics such as isotopic ratios and trace elements. Through novel implementation of machine learning and pattern recognition techniques it is envisaged that spectral analysis will become faster and more accurate. Rather than using the ratios of specific isotopes and specific elemental compositions for analysis we have shown that machine learning allows the user to make use of the full extent of elemental and isotopic data available. These techniques have further been able to provide an effective set of tools for finding valuable insight into the provenance of a particular sample utilizing the posterior probability distribution of samples from a given reference dataset. Our work has focused on finding novel and effective machine learning techniques to aid the nuclear forensics process by providing visualisation of the complex datasets that result from spectral analysis of radioactive samples as well as generating classification models for determining attributes such as reactor design or the age of a given sample. A number of classification and visualisation techniques have been successfully tested on a set of datasets that are representative of a number of different radioactive substances from the nuclear fuel lifecycle. While each of these substances have their own challenges to address in terms of source determination, our work has successfully addressed the need to provide a well- informed analysis of the nuances of these datasets to effectively and accurately utilise the characteristics of the materials to make an informed decision regarding the origin of the substance. For instance, a representative dataset of post-irradiation samples have been used to demonstrate an effective classification model for determining the reactor design from which a sample may have originated. This analysis has been further supported by dimensional reduction techniques to generate visualisation of the dataset such that further conclusions can be drawn from the spread of the data. Results show that these techniques are very much capable of classifying spent reactor fuel with a level of accuracy that would certainly aid the decision making process with regards to determining the source of unknown substances in the fight against nuclear smuggling.},
  author = {Jones, Andrew and Turner, Phillip and Zimmerman, Colin and Goulermas, J.Y.},
  month = {May},
  year = {2014}
}

@article{jones_snf_2014,
  title = {Classification of Spent Reactor Fuel for Nuclear Forensics},
  volume = {86},
  eprint = {http://pubs.acs.org/doi/ipdf/10.1021/ac5004757},
  doi = {dx.doi.org/10.1021/ac5004757}, 
  abstract = {In this paper we demonstrate the use of pattern recognition and machine learning techniques to determine the reactor type from which spent reactor fuel has originated. This has been done using the isotopic and elemental measurements of the sample and proves to be very useful in the field of nuclear forensics. Nuclear materials contain many variables (impurities and isotopes) that are very difficult to consider individually. A method that considers all material parameters simultaneously is advantageous. Currently the field of nuclear forensics focuses on the analysis of key material properties to determine details about the materials processing history, for example, utilizing known half-lives of isotopes can determine when the material was last processed (Stanley, F. E. J. Anal. At. Spectrom. 2012, 27, 1821; Varga, Z.; Wallenius, M.; Mayer, K.; Keegan, E.; Millet, S. Anal. Chem. 2009, 81, 8327−8334). However, it has been demonstrated that multivariate statistical analysis of isotopic concentrations can complement these method and are able to make use of a greater level of information through dimensionality reduction techniques (Robel, M.; Kristo, M. J. J. Environ. Radioact. 2008, 99, 1789−1797; Robel, M.; Kristo, M. J.; Heller, M. A. Nuclear Forensic Inferences Using Iterative Multidimensional Statistics. In Proceedings of the Institute of Nuclear Materials Management 50th Annual Meeting, Tucson, AZ, July 2009; 12 pages; Nicolaou, G. J. Environ. Radioact. 2006, 86, 313−318; Pajo, L.; Mayer, K.; Koch, L. Fresenius’ J. Anal. Chem. 2001, 371, 348−352). There has been some success in using such multidimensional statistical methods to determine details about the history of spent reactor fuel (Robel, M.; Kristo, M. J.J. Environ. Radioact.2008,99,1789−1797). Here, we aim to expand on these findings by pursuing more robust dimensionality reduction techniques based on manifold embedding which are able to better capture the intrinsic data set information. Furthermore, we demonstrate the use of a number of classification algorithms to reliably determine the reactor type in which a spent fuel material has been irradiated. A number of these classification techniques are novel applications in nuclear forensics and expand on the existing knowledge in this field by creating a reliable and robust classification model. The results from this analysis show that our techniques have been very successful and further ascertain the excellent potential of these techniques in the field of nuclear forensics at least with regard to spent reactor fuel.},
  journal = {Analytical Chemistry},
  author = {Jones, Andrew E. and Turner, Phillip and Zimmerman, Colin and Goulermas, John Y.},
  year = {2014},
  pages = {5399--5405}
}

@inproceedings{weber_2006,
  address = {Albuquerque, NM, USA},
  title = {Inverse Depletion/Decay Analysis Using the SCALE Code System},
  booktitle = {{Transactions} of the {American Nuclear Society Winter Meeting}},
  author = {Weber, Chuck F and Broadhead, Bryan L},
  year = {2006}, 
  volume = {95},
  pages = {248--249},
  note = {Track 4: Nuclear and Criticality Safety Technologies},
}

@inproceedings{weber_2010,
  address = {Baltimore, MD, USA},
  title = {Validation of Inverse Methods Applied to Forensic Analysis of Spent Fuel},
  booktitle = {{Proceedings} of the {Institute} of {Nuclear Materials Management} 51st {Annual Meeting}},
  abstract = {Inverse depletion/decay methods are useful tools for application to nuclear forensics.  Previously, inverse methods were applied to the generic case of predicting the burnup, initial enrichment, and cooling time for selected spent nuclear fuels based on measured actinide and fission product concentrations.  These existing measurements were not developed or optimized for use by these inverse techniques, and hence previous work demonstrated the prediction of only the fuel burnup, initial enrichment, and cooling time.  Previously nine spent fuel samples from an online data compilation were randomly selected for study.  This work set out to demonstrate the full prediction capabilities using measured isotopic data, but with a more deliberate selection of fuel samples.  The current approach is to evaluate nuclides within the same element to see if complementary information can be obtained in addition to the reactor burnup, enrichment, and cooling.  Specifically, the reactor power and the fuel irradiation time values are desired to achieve the maximum prediction capabilities of these techniques.},
  author = {Broadhead, Bryan L and Weber, Charles F},
  year = {2010}, 
  eprint = {https://www.osti.gov/scitech/biblio/1001291}
}

@inproceedings{weber_2011,
  address = {Palm Desert, CA, USA},
  title = {Inverse Solutions in Spectroscopic Analysis with Applications to Problems in Global Safeguards},
  booktitle = {{Proceedings} of the {Institute} of {Nuclear Materials Management} 52nd {Annual Meeting}},
  abstract = {This work describes a nondestructive strategy and algorithm designed to evaluate the burnup and plutonium content of light-water-reactor spent fuel and thereby confirm declared values. In contrast with previous methods that focus on only a few photopeaks (e.g., 137 Cs at 662 keV), the present approach involves the entire gamma spectrum up to 2000 keV. Spectra are used as input for the inverse code INDEPTH, which is designed to predict reactor parameters (fuel enrichment, power level, irradiation time, and cooling time) when given either a set of nuclide inventories or the gamma spectrum that they produce. This approach has the advantage of often making possible the determination of parameters other than burnup when they are unknown or in doubt. In addition, error in one photopeak evaluation is mitigated by the inclusion of the entire spectrum. The solution procedure involves multiple runs of the forward code ORIGEN/ARP, each of which produces an extensive list of nuclides formed through depletion/decay processes. The gamma spectrum of these nuclides is compared with the gamma spectrum from a detector through a bin-by-bin sum of squared error. New choices for the reactor parameters that are input to ORIGEN/ARP are determined using a gradient search technique, and the best parameter set is that which minimizes the squared error between calculated and measured gamma spectra. The method is applied to the analysis of gamma data taken from various sections of actual spent reactor fuel and is compared with declared values and other methods of evaluation. The sensitivity of the inverse solution with respect to various parameters is calculated and indicates that the algorithm is stable and robust. One example includes the presence of multiple solutions, each of which can be characterized using additional information.},
  author = {Weber, Charles F and Protopopescu, Vladimir A and Ehinger, Michael H and Solodov, Alexander A and Romano, Catherine E},
  year = {2011}, 
  eprint = {https://www.osti.gov/scitech/biblio/1031530}
}

@inbook{inverse_theory,
  author = {Albert Tarantola},
  year = {2005},
  address = {Philadelphia, Pennsylvania, USA},
  publisher = {Society for Industrial and Applied Mathematics},
  title = {{Inverse Problem Theory} and {Methods} for {Model Parameter Estimation}},
  chapter = {1. {The General Discrete Inverse Problem}},
  pages = {1--40},
  doi = {10.1137/1.9780898717921.ch1},
  URL = {http://epubs.siam.org/doi/abs/10.1137/1.9780898717921.ch1},
  eprint = {http://epubs.siam.org/doi/pdf/10.1137/1.9780898717921.ch1}
}

@book{nftext_2005,
  title={{Nuclear Forensic Analysis}},
  author={Moody, K.J. and Grant, P.M. and Hutcheon, I.D.},
  address={Boca Raton, Florida, USA},
  edition={1},
  isbn={9780203507803},
  eprint={https://books.google.com/books?id=Q9mgDnWoPLYC},
  year={2005},
  publisher={CRC Press}
}

@inproceedings{osg07,
  title  = {The open science grid},
  author = {
    Pordes, Ruth 
    and Petravick, Don 
    and Kramer, Bill 
    and Olson, Doug 
    and Livny, Miron 
    and Roy, Alain 
    and Avery, Paul 
    and Blackburn, Kent 
    and Wenaus, Torre 
    and W{\"u}rthwein, Frank 
    and Foster, Ian
    and Gardner, Rob
    and Wilde, Mike
    and Blatecky, Alan
    and McGee, John
    and Quick, Rob
  },
  doi       = {10.1088/1742-6596/78/1/012057},
  booktitle = {J. Phys. Conf. Ser.},
  volume    = {78},
  series    = {78},
  pages     = {012057},
  year      = {2007},
}

@inproceedings{osg09,
  title        = {The pilot way to grid resources using glideinWMS},
  author       = {
    Sfiligoi, Igor    
    and Bradley, Daniel C 
    and Holzman, Burt     
    and Mhashilkar, Parag 
    and Padhi, Sanjay     
    and Wurthwein, Frank
  },
  doi          = {10.1109/CSIE.2009.950},
  booktitle    = {2009 WRI World Congress on Computer Science and Information Engineering},
  volume       = {2},
  series       = {2},
  pages        = {428--432},
  year         = {2009},
}

@article{scikit,
  title={Scikit-learn: Machine Learning in {P}ython},
  author  = {Fabian Pedregosa and Ga{{\"e}}l Varoquaux and Alexandre Gramfort and Vincent Michel and Bertrand Thirion and Olivier Grisel and Mathieu Blondel and Peter Prettenhofer and Ron Weiss and Vincent Dubourg and Jake Vanderplas and Alexandre Passos and David Cournapeau and Matthieu Brucher and Matthieu Perrot and {{\'E}}douard Duchesnay},
  title   = {Scikit-learn: Machine Learning in Python},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {85},
  pages   = {2825-2830},
  eprint  = {http://jmlr.org/papers/v12/pedregosa11a.html}
}

@InProceedings{ pandas,
  author    = { {W}es {M}c{K}inney },
  title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
  booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
  pages     = { 56 - 61 },
  year      = { 2010 },
  editor    = { {S}t\'{e}fan van der {W}alt and {J}arrod {M}illman },
  eprint    = { http://conference.scipy.org/proceedings/scipy2010/pdfs/mckinney.pdf },
  doi       = { 10.25080/Majora-92bf1922-00a }
}

@ARTICLE{matplotlib,
  author={Hunter, John D.},
  journal={Computing in Science Engineering},
  title={Matplotlib: A 2D Graphics Environment}, 
  year={2007},
  volume={9},
  number={3},
  pages={90-95},
  eprint={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4160265},
  doi={10.1109/MCSE.2007.55}
}

@ARTICLE{ipython,
  author={Perez, Fernando and Granger, Brian E.},
  journal={Computing in Science Engineering}, 
  title={IPython: A System for Interactive Scientific Computing}, 
  year={2007},
  volume={9},
  number={3},
  pages={21-29},
  eprint={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4160251},
  doi={10.1109/MCSE.2007.53}
}

@ARTICLE{scipy,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  eprint  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@ARTICLE{numpy,
  author  = {Harris, Charles R. and Millman, K. Jarrod and
            van der Walt, Stéfan J and Gommers, Ralf and
            Virtanen, Pauli and Cournapeau, David and
            Wieser, Eric and Taylor, Julian and Berg, Sebastian and
            Smith, Nathaniel J. and Kern, Robert and Picus, Matti and
            Hoyer, Stephan and van Kerkwijk, Marten H. and
            Brett, Matthew and Haldane, Allan and
            Fernández del Río, Jaime and Wiebe, Mark and
            Peterson, Pearu and Gérard-Marchant, Pierre and
            Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and
            Abbasi, Hameer and Gohlke, Christoph and
            Oliphant, Travis E.},
  title   = {Array programming with {NumPy}},
  journal = {Nature},
  year    = {2020},
  volume  = {585},
  pages   = {357–362},
  eprint  = {https://www.nature.com/articles/s41586-020-2649-2},
  doi     = {10.1038/s41586-020-2649-2}
}

@techreport{gadras, 
  address={Albuquerque, New Mexico, USA},
  institution={Sandia National Laboratories},
  title={{Gamma Detector Response} and {Analysis Software} - {Detector Response Function (GADRAS-DRF)}},
  type={{User's Manual}}, 
  eprint={http://www.osti.gov/scitech/servlets/purl/1166695}, 
  DOI={10.2172/1166695}, 
  abstractNote={The Gamma Detector Response and Analysis Software - Detector Response Function (GADRAS-DRF) application computes the response of gamma-ray and neutron detectors to incoming radiation. This manual provides step-by-step procedures to acquaint new users with the use of the application. The capabilities include characterization of detector response parameters, plotting and viewing measured and computed spectra, analyzing spectra to identify isotopes, and estimating source energy distributions from measured spectra. GADRAS-DRF can compute and provide detector responses quickly and accurately, giving users the ability to obtain usable results in a timely manner (a matter of seconds or minutes).}, 
  author={Horne, Steven M. and Thoreson, Gregory G and Theisen, Lisa A. and Mitchell, Dean J. and Harding, Lee and Amai, Wendy A.}, 
  year={2014}, 
  month={Dec},
  note = {Version 18.5; SAND2014-19465},
}

@techreport{scale,
  author = {{Oak Ridge National Laboratory}},
  institution = {{Oak Ridge National Laboratory}},
  address = {Oak Ridge, Tennessee, USA},
  title = {{SCALE: A Comprehensive Modeling} and {Simulation Suite} for {Nuclear Safety Analysis} and {Design}},
  year = {2018},
  month={Mar},
  eprint = {http://scale.ornl.gov},
  note = {Version 6.2.3, ORNL/TM-2005/39, Available from Radiation Safety Information Computational Center as CCC-834},
  type = {Code Suite}
}

@inproceedings{origen,
  address = {Oak Ridge, Tennessee, USA},
  author = {B.T. Rearden and M.A. Jessee},
  publisher = {{Oak Ridge National Laboratory}},
  booktitle = {{SCALE Code System: User Documentation}},
  title = {Ch. 5 {Depletion, Activation}, and {Spent Fuel Source Terms}},
  pages = {5-1--5-263},
  year = {2018},
  month = {Mar},
  eprint = {https://www.ornl.gov/sites/default/files/SCALE\%20Code\%20System.pdf},
  note = {Version 6.2.3; ORNL/TM-2005/39},
}

@techreport{origenarp,
  title = {{OrigenArp} {Primer}: {How} to {Perform} {Isotopic} {Depletion} and {Decay} {Calculations} with {SCALE}/{ORIGEN}},
  shorttitle = {{OrigenArp} {Primer}},
  eprint = {http://www.osti.gov/servlets/purl/986788/},
  language = {en},
  number = {ORNL/TM-2010/43, 986788},
  institution = {Oak Ridge National Laboratory},
  author = {Bowman, Stephen M and Gauld, Ian C},
  month = aug,
  year = {2010},
  doi = {10.2172/986788},
  pages = {ORNL/TM--2010/43, 986788},
}

@article{skutnik_2016,
  title = {Characterization of the non-uniqueness of used nuclear fuel burnup signatures through a {Mesh}-{Adaptive} {Direct} {Search}},
  volume = {817},
  eprint = {http://www.sciencedirect.com/science/article/pii/S0168900216001571?via\%3Dihub},
  doi = {http://dx.doi.org/10.1016/j.nima.2016.02.007},
  abstract = {The use of passive gamma and neutron signatures from fission indicators is a common means of estimating used fuel burnup, enrichment, and cooling time. However, while characteristic fission product signatures such as 134Cs, 137Cs, 154Eu, and others are generally reliable estimators for used fuel burnup within the context where the assembly initial enrichment and the discharge time are known, in the absence of initial enrichment and/or cooling time information (such as when applying NDA measurements in a safeguards/verification context), these fission product indicators no longer yield a unique solution for assembly enrichment, burnup, and cooling time after discharge. Through the use of a new Mesh-Adaptive Direct Search (MADS) algorithm, it is possible to directly probe the shape of this “degeneracy space” characteristic of individual nuclides (and combinations thereof), both as a function of constrained parameters (such as the assembly irradiation history) and unconstrained parameters (e.g., the cooling time before measurement and the measurement precision for particular indicator nuclides). In doing so, this affords the identification of potential means of narrowing the uncertainty space of potential assembly enrichment, burnup, and cooling time combinations, thereby bounding estimates of assembly plutonium content. In particular, combinations of gamma-emitting nuclides with distinct half-lives (e.g., 134Cs with 137Cs and 154Eu) in conjunction with gross neutron counting (via 244Cm) are able to reasonably constrain the degeneracy space of possible solutions to a space small enough to perform useful discrimination and verification of fuel assemblies based on their irradiation history.},
  journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  author = {Skutnik, Steven E. and Davis, David R.},
  year = {2016},
  pages = {7--18}
}

@article{endf,
  title = {ENDF/B-VII.1 Nuclear Data for Science and Technology: Cross Sections, Covariances, Fission Product Yields and Decay Data},
  journal = {Nuclear Data Sheets},
  volume = {112},
  number = {12},
  pages = {2887--2996},
  year = {2011},
  eprint = {http://www.sciencedirect.com/science/article/pii/S009037521100113X},
  author = {M.B. Chadwick and M. Herman and P. Oblo\v{z}insk\'{y} and M.E. Dunn and Y. Danon and A.C. Kahler and D.L. Smith and B. Pritychenko and G. Arbanas and R. Arcilla and R. Brewer and D.A. Brown and R. Capote and A.D. Carlson and Y.S. Cho and H. Derrien and K. Guber and G.M. Hale and S. Hoblit and S. Holloway and T.D. Johnson and T. Kawano and B.C. Kiedrowski and H. Kim and S. Kunieda and N.M. Larson and L. Leal and J.P. Lestone and R.C. Little and E.A. McCutchan and R.E. MacFarlane and M. MacInnes and C.M. Mattoon and R.D. McKnight and S.F. Mughabghab and G.P.A. Nobre and G. Palmiotti and A. Palumbo and M.T. Pigni and V.G. Pronyaev and R.O. Sayer and A.A. Sonzogni and N.C. Summers and P. Talou and I.J. Thompson and A. Trkov and R.L. Vogt and S.C. van der Marck and A. Wallner and M.C. White and D. Wiarda and P.G. Young}
}

@article{pyne,
  title = {{PyNE Progress Report}},
  author = {Bates, {Cameron R.} and Elliott Biondo and Kathryn Huff and Kalin Kiesling and Anthony Scopatz and Robert Carlsen and Andrew Davis and Matthew Gidden and Tim Haines and Joshua Howland and Blake Huff and Kevin Manalo and Arielle Opotowsky and Rachel Slaybaugh and Eric Relson and Paul Romano and Patrick Shriwise and Xia, {John D.} and Paul Wilson and Julie Zachman},
  year = {2014},
  month = jan,
  day = {1},
  volume = {111},
  pages = {1165--1168},
  journal = {{Transactions of the American Nuclear Society}},
  issn = {0003-018X},
  note = {2014 ANS Winter Meeting and Nuclear Technology Expo ; Conference date: 09-11-2014 Through 13-11-2014},
}

@article{sfcompo,
  title = {{SFCOMPO}-2.0: {An} {OECD} {NEA} database of spent nuclear fuel isotopic assays, reactor design specifications, and operating data},
  volume = {110},
  issn = {0306-4549},
  shorttitle = {{SFCOMPO}-2.0},
  doi = {10.1016/j.anucene.2017.07.022},
  abstract = {SFCOMPO-2.0 is the new release of the Organisation for Economic Co-operation and Development (OECD) Nuclear Energy Agency (NEA) database of experimental assay measurements. These measurements are isotopic concentrations from destructive radiochemical analyses of spent nuclear fuel (SNF) samples. The measurements are supplemented with design information for the fuel assembly and fuel rod from which each sample was taken, as well as with relevant information on operating conditions and characteristics of the host reactors. These data are necessary for modeling and simulation of the isotopic evolution of the fuel during irradiation. SFCOMPO-2.0 has been developed and is maintained by the OECD NEA under the guidance of the Expert Group on Assay Data of Spent Nuclear Fuel (EGADSNF), which is part of the NEA Working Party on Nuclear Criticality Safety (WPNCS). Significant efforts aimed at establishing a thorough, reliable, publicly available resource for code validation and safety applications have led to the capture and standardization of experimental data from 750 SNF samples from more than 40 reactors. These efforts have resulted in the creation of the SFCOMPO-2.0 database, which is publicly available from the NEA Data Bank. This paper describes the new database, and applications of SFCOMPO-2.0 for computer code validation, integral nuclear data benchmarking, and uncertainty analysis in nuclear waste package analysis are briefly illustrated.},
  number = {Supplement C},
  journal = {Annals of Nuclear Energy},
  author = {Michel-Sendis, F. and Gauld, I. and Martinez, J. S. and Alejano, C. and Bossant, M. and Boulanger, D. and Cabellos, O. and Chrapciak, V. and Conde, J. and Fast, I. and Gren, M. and Govers, K. and Gysemans, M. and Hannstein, V. and Havl\r{u}j, F. and Hennebach, M. and Hordosy, G. and Ilas, G. and Kilger, R. and Mills, R. and Mountford, D. and Ortego, P. and Radulescu, G. and Rahimi, M. and Ranta-Aho, A. and Rantam\"{a}ki, K. and Ruprecht, B. and Soppera, N. and Stuke, M. and Suyama, K. and Tittelbach, S. and Tore, C. and Winckel, S. Van and Vasiliev, A. and Watanabe, T. and Yamamoto, Toru and Yamamoto, Toshihisa},
  month = dec,
  year = {2017},
  keywords = {Code validation, Experimental isotopic compositions, Integral benchmarks, Nuclear fuel depletion, Nuclear fuel evolution, Radiochemical assay data, SFCOMPO, Spent nuclear fuel database},
  pages = {779--788},
  eprint = {http://www.sciencedirect.com/science/article/pii/S0306454917302104},
}

@article{valid_sfco_2017,
  title = {Integral nuclear data validation using experimental spent nuclear fuel compositions},
  volume = {49},
  issn = {17385733},
  eprint = {https://linkinghub.elsevier.com/retrieve/pii/S1738573317303054},
  doi = {10.1016/j.net.2017.07.002},
  language = {en},
  number = {6},
  journal = {Nuclear Engineering and Technology},
  author = {Gauld, Ian C. and Williams, Mark L. and Michel-Sendis, Franco and Martinez, Jesus S.},
  month = sep,
  year = {2017},
  pages = {1226--1233},
}

@techreport{pwr_assay_2019,
  title = {Review of {Experimental} {Assay} {Data} for {PWR} {Spent} {Fuel}},
  eprint = {https://www.osti.gov/servlets/purl/1782069/},
  number = {ORNL/SPR--2019/1143, 1782069},
  author = {Ilas, Germina},
  month = apr,
  year = {2019},
  doi = {10.2172/1782069},
  pages = {ORNL/SPR--2019/1143, 1782069},
}

@techreport{pwr_benchmark_2010,
  title = {{SCALE} 5.1 {Predictions} of {PWR} {Spent} {Nuclear} {Fuel} {Isotopic} {Compositions}},
  eprint = {http://www.osti.gov/servlets/purl/983556/},
  language = {en},
  number = {ORNL/TM-2010/44, 983556},
  author = {Radulescu, Georgeta and Gauld, Ian C and Ilas, Germina},
  month = mar,
  year = {2010},
  doi = {10.2172/983556},
  pages = {ORNL/TM--2010/44, 983556},
}

@techreport{skutnik_2021,
  title = {{ORIGEN}-based {Nuclear} {Fuel} {Inventory} {Module} for {Fuel} {Cycle} {Assessment}: {Final} {Project} {Report}},
  shorttitle = {{ORIGEN}-based {Nuclear} {Fuel} {Inventory} {Module} for {Fuel} {Cycle} {Assessment}},
  eprint = {http://www.osti.gov/servlets/purl/1364128/},
  language = {en},
  number = {DOE/NEUP--13-5415, 1364128},
  author = {Skutnik, Steven E.},
  month = jun,
  year = {2017},
  doi = {10.2172/1364128},
  pages = {DOE/NEUP--13--5415, 1364128},
}

@techreport{lwr_valid, 
  author = {L. C. Leal and O. W. Hermann and S. M. Bowman and C. V. Parks}, 
  title = {ARP: Automatic Rapid Process for the Generation of Problem-Dependent SAS2H/ORIGEN-S Cross-Section Libraries}, 
  note = {ORNL/TM-13584},
  institution = {Lockheed Martin Energy Research Corporation and Oak Ridge National Laboratory}, 
  month = apr, 
  year = 1998, 
  eprint = {https://digital.library.unt.edu/ark:/67531/metadc684948/},
}

@techreport{mox_valid,
  author = {I. C. Gauld}, 
  title = {MOX Cross-Section Libraries for ORIGEN-ARP}, 
  note = {ORNL/TM-2003/2}, 
  institution = {UT-Battelle, LLC and Oak Ridge National Laboratory}, 
  month = jul,
  year = 2003,
  eprint = {https://www.nrc.gov/docs/ML0410/ML041040058.pdf},
}


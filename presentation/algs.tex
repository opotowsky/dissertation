\begin{frame}
  \frametitle{k-Nearest Neighbors}
  \begin{adjustwidth}{-10pt}{0pt}
  \begin{minipage}{0.5\textwidth}
    \begin{block}{Objective}
      Minimum distance between test sample and training instance(s)
    \end{block}
    \begin{block}{Algorithm hyperparameters:}
      \begin{itemize}
        \item k \textit{(1-7)}
        \item Distance measure \textit{(Manhattan distance)}
        \item Weight of nearest neighbors: uniform or distance \textit{(distance)}
      \end{itemize}
    \end{block}
  \end{minipage}
  \hfill
  \begin{minipage}{0.5\textwidth}
    \begin{figure}
      \centering
      \includegraphics[height=0.5\textheight]{./figures/nn-fig.png}
    \end{figure}
  \end{minipage}
  \end{adjustwidth}
\end{frame}

\begin{frame}
  \frametitle{Decision Trees}
  \begin{adjustwidth}{-10pt}{0pt}
  \begin{minipage}{0.4\textwidth}
    \begin{block}{Objective:}
      Minimum node impurity at each split
    \end{block}
    \begin{block}{Algorithm hyperparameters:}
      \begin{itemize}
        \item Maximum \# of features \textit{(num nuclides, or 150)}
        \item Maximum depth \textit{(41-78)}
        \item Criterion \textit{(Scikit defaults: gini \& mean squared error)}
      \end{itemize}
    \end{block}
  \end{minipage}
  \hfill
  \begin{minipage}{0.6\textwidth}
    \begin{figure}
      \centering
      \includegraphics[width=\textwidth]{./figures/dtree.png}
    \end{figure}
  \end{minipage}
  \end{adjustwidth}
\end{frame}

\begin{frame}
  \frametitle{Maximum Likelihood Calculations}

Likelihood calculated is as follows:
\[
  L(M|x_{test}) = \prod_i \frac{1}{\sigma_{i,train} \sqrt{2\pi}} \exp{\frac{-(x_{i,test} - x_{i,train})^2}{2 \sigma_{i,train}^2}}
\]

Whereas the log-likelihood is used in practice:
\[
  ln(L(M|x_{test})) = \sum_i ln(\frac{1}{\sigma_{i,train} \sqrt{2\pi}}) - \frac{(x_{i,test} - x_{i,train})^2}{2 \sigma_{i,train}^2}
\]

Approach based on previous work: \cite{mll_method} \\~\\

\end{frame}
